# 多节点限流参数调整说明

## 背景
在 5 节点（127.0.0.1:9991~9995）场景下进行 250 次混合 CRUD 压测（10 线程×20 次/线程 + 预创建 50 次），日志显示失败主要集中在 429（限流），如下：

- 成功约 42～44 次，失败约 206～208 次
- 错误码分布：429 ≈ 143 次、409 ≈ 49～51 次、404 ≈ 14 次
- 一致性哈希导致请求在各节点分布略有倾斜（存在热点），加剧热点节点的限流触发

## 原限流配置问题
- 默认使用 `TokenBucketRateLimit`，在 `RateLimitProvider` 中的默认构造为：`new TokenBucketRateLimit(100, 10)`
- 按实现参数语义：
  - `rate=100` 表示每 100ms 生成 1 个令牌，约 10 QPS/节点
  - `capacity=10` 表示桶容量为 10，抗突发能力较弱
- 在 5 节点下，总理论放行 ≈ 50 QPS，且由于请求突发与热点，触发 429 的概率很高

## 调整目标
- 提升每节点吞吐到 ~100 QPS
- 增强对突发与热点的缓冲能力，降低 429 出现概率

## 调整内容
- 将默认限流参数调整为：`new TokenBucketRateLimit(10, 300)`
  - `rate=10`：每 10ms 生成 1 个令牌，约 100 QPS/节点
  - `capacity=300`：桶容量 300，能够更好地吸收突发流量与热点 key 带来的瞬时倾斜

## 影响评估
- 正向影响：显著降低 429（限流）比例，提高整体成功率；多节点下更能体现水平扩展收益
- 潜在风险：若下游（数据库/存储）承载能力有限，可能需要同步扩容下游或再叠加服务端并发/队列控制

## 回滚方案
- 将 `RateLimitProvider` 中的默认参数恢复为 `new TokenBucketRateLimit(100, 10)`
- 或根据需要设为其他更保守值，例如 `new TokenBucketRateLimit(20, 100)`（约 50 QPS/节点）

## 验证步骤
1. 启动多节点：`server.MultiNodeServer`
2. 运行并发客户端：`client.ConcurrentTestClient`
3. 观察 `logs/rpc.yyyy-MM-dd.log`：
   - 成功数显著上升
   - 429 次数明显下降
   - 节点分布依旧可能存在轻微倾斜（由一致性哈希与 key 分布决定，属预期）

## 后续建议（可选）
- 将限流参数改为可配置（如从 properties/环境变量读取），便于不同环境快速调参
- 如需进一步均衡热点，可在压测阶段临时切换为 `ROUND_ROBIN`/`RANDOM`，或扩大 userId 空间、优化 key 分布


